The one-way Analysis of Variance (ANOVA) is used with one categorical independent variable and one continuous variable. The independent variable can consist of any number of groups (levels).

OBS.: The t-test, which is often used in similar experiments with two group, is only appropriate for situations where there are only two levels of one independent variable. When there is a categorical independent variable and a continuous dependent variable and there are more than two levels of the independent variable and/or there is more than one independent variable (a case that would require a multi-way, as opposed to one way ANOVA), then the appropriate analysis is the work horse of experimental psychology research, the analysis of variance.

In the case where there are more than two levels of the independent variable the analysis goes through two steps.

I-) First, we carry out an over-all F test to determine if there is any significant difference existing among any of the means.
II-) If this F score is statistically significant, then we carry out a second step in which we compare sets of two means at a time in order to determine specifically, where the significance difference lies. 

The "Between Groups" row represents what is often called "explained variance" or "systematic variance". We can think of this as variance that is due to the independent variable, the difference among the three groups. For example the difference between a person's score in group one and a person's score in group two would represent explained variance.

#OBS.: Between Group Variability just as we calculate the standard deviation


The "Within Groups" variance represents what is often called "error variance". This is the variance within your groups, variance that is not due to the independent variable. For example, the difference between one person in group one and another person in group one would represent error variance

First, which means are significantly different from which other means and, second what were the actual scores of the group?
To answer the pair comparisons questions we run a series of Tukey's post-hoc tests, which are like a series of t-tests. The post-hoc tests are more stringent than the regular t-tests however, due to the fact that the more tests you perform the more likely it is that you will find a significant difference just by chance. Your post hoc tests which statistical programs often presented in a table, might look something like this:

y<-c(1,2,3,4,5,6,7,8)
cs<-c(7,4,6,8,6,6,2,9)
rs<-c(5,5,3,4,4,7,2,2)
ns<-c(2,4,7,1,2,1,5,5)

mean(cs)
var(cs)
sd(cs)
sum(cs)
sum(cs)^2


mean(rs)
var(rs)
sd(rs)
sum(rs)
sum(rs)^2
rs^2

mean(ns)
var(ns)
sd(ns)
sum(ns)
sum(ns)^2
ns^2

n<-8
n2<-n*3

SST<- sum(cs^2)+ sum(rs^2)+ sum(ns^2)-(sum(cs)+sum(rs)+sum(ns))^2/n2
SSA<-(sum(cs)^2+sum(rs)^2+sum(ns)^2)/n-(sum(cs)+sum(rs)+sum(ns))^2/n2
SSW<-SST-SSA

with df = (2,21) F must be at least 3.4668 to reach p < .05, so F score is statistically significant)

Interpretation: Susan can conclude that her hypothesis may be supported. The means are as she predicted, in that the constant music group has the highest score. However, the signficant F only indicates that at least two means are signficantly different from one another, but she can't know which specific mean pairs significantly differ until she conducts a post-hoc analysis (e.g., Tukey's HSD).



D<-data.frame(y<-c(1,2,3,4,5,6,7,8),cs<-c(7,4,6,8,6,6,2,9),
rs<-c(5,5,3,4,4,7,2,2),
ns<-c(2,4,7,1,2,1,5,5))

aov.ex1 = aov(y~cs+rs+ns,data=D)  #do the analysis of variance
summary(aov.ex1)                                    #show the summary table
print(model.tables(aov.ex1,"means"),digits=3)       #report the means and the number of subjects/cell
boxplot(y~cs+rs+ns,data=D)        #graphical summary

D2<-data.frame(y<-c(1,2,3,4,5,6,7,8),cs<-c(7,4,6,8,6,6,2,9),
rs<-c(5,5,3,4,4,7,2,2),
ns<-c(2,4,7,1,2,1,5,5))

aov.ex2 = aov(cs~rs*ns,data=D2)         #do the analysis of variance
summary(aov.ex2)                                    #show the summary table
print(model.tables(aov.ex2,"means"),digits=3)       #report the means and the number of subjects/cell
boxplot(y~cs*rs*ns,data=D2) #graphical summary of means of the 4 cells

D3<-data.frame(y<-c(1,2,3,4,5,6,7,8),cs<-c(7,4,6,8,6,6,2,9),
rs<-c(5,5,3,4,4,7,2,2),
ns<-c(2,4,7,1,2,1,5,5))
aov.ex3 = aov(y~cs*rs*ns,data=D3)
summary(aov.ex3)
print(model.tables(aov.ex3,"means"),digits=3)       #report the means and the number of subjects/cell
boxplot(y~cs*rs*ns,data=D3)          #graphical output

A 4 5 4 3 2 4 3 4 4
B 6 8 4 5 4 6 5 8 6
C 6 7 6 6 7 5 6 5 5
pain = c(4, 5, 4, 3, 2, 4, 3, 4, 4, 6, 8, 4, 5, 4, 6, 5, 8, 6, 6, 7, 6, 6, 7, 5, 6, 5, 5)
drug = c(rep("A",9), rep("B",9), rep("C",9))
migraine = data.
frame(pain,drug)
migraine
plot(pain ~ drug, data=migraine)
Next, the R function aov() can be used for fitting ANOVA models. The general form is aov(response ~ factor, data=data_name) where response represents the response variable and factor the variable that separates the data into groups. Both variables should be contained in the data frame called data_name. Once the ANOVA model is fit, one can look at the results using the summary() function. This produces the standard ANOVA table.Ex. Drug company example continued.

results = aov(pain ~ drug, data=migraine)
summary(results)

Studying the output of the ANOVA table above we see that the F-statistic is 11.91 with a p-value equal to 0.0003. We clearly reject the null hypothesis of equal means for all three drug groups. 

The ANOVA F-test answers the question whether there are significant differences in the K population means. However, it does not provide us with any information about how they differ. Therefore when you reject H0 in ANOVA, additional analyses are required to determine what is driving the difference in means. The function pairwise.t.test computes the pair-wise comparisons between group means with corrections for multiple testing. The general form is

pairwise.t.test(reponse, factor, p.adjust = method, alternative = c("two.sided",
"less", "greater"))

Here response is a vector of observations (the response variable), factor a list of factors and p.adjust is the correction method (e.g., “Bonferroni”). Ex. Drug company example continued.

pairwise.t.test(pain, drug, p.adjust="bonferroni")

The results state that the difference in means is not significantly different between drugs B and C (p-value = 1.00), but both are significantly different from drug A (p-values = 0.00119 and 0.00068, respectively). Hence, we can conclude that the mean pain is significantly different for drug A.   Another multiple comparisons procedure is Tukey‟s method (a.k.a. Tukey's Honest Significance Test). The function TukeyHSD() creates a set of confidence intervals on the differences between means with the specified family-wise
probability of coverage. The general form is TukeyHSD(x, conf.level = 0.95) Here x is a fitted model object (e.g., an aov fit) and conf.level is the confidence level.Ex. Drug company example continued.


results = aov(pain ~ drug, data=migraine)
TukeyHSD(results, conf.level = 0.95)

These results show that the B-A and C-A differences are significant (p=0.0011 and p=0.00065, respectively), while the C-B difference is not (p=0.97). This confirms the results obtained using Bonferroni correction




